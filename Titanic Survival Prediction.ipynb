{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-11T04:51:29.676731300Z",
     "start_time": "2023-10-11T04:51:29.645786100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Model-related imports\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Pre-processing and feature extraction\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Model evaluation and hyperparameter tuning\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "baseline = pd.read_csv('gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "def preprocess_data_advanced(data):\n",
    "    #Titles of people\n",
    "    data['Title'] = data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    data['Title'] = data['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Other')\n",
    "    data['Title'] = data['Title'].replace('Mlle', 'Miss')\n",
    "    data['Title'] = data['Title'].replace('Ms', 'Miss')\n",
    "    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "    #Family Size\n",
    "    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "\n",
    "    #Groupings by age\n",
    "    bins = [0, 12, 20, 40, 60, np.inf]\n",
    "    labels = ['Child', 'Teenager', 'Adult', 'MiddleAge', 'Senior']\n",
    "    data['AgeGroup'] = pd.cut(data['Age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "    #Cabins\n",
    "    data['Deck'] = data['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n",
    "\n",
    "    # Handle missing values\n",
    "    data['Age'].fillna(data['Age'].mean(), inplace=True)\n",
    "    data['Fare'].fillna(data['Fare'].mean(), inplace=True)\n",
    "    data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)  # Fill with the most frequent value\n",
    "\n",
    "    # Log Transformation on Fare // New Addition thoughts?\n",
    "    data['Fare'] = np.log1p(data['Fare'])\n",
    "\n",
    "    # Encoding categorical variables\n",
    "    data = pd.get_dummies(data, columns=['Sex', 'Pclass', 'Embarked', 'AgeGroup', 'Title', 'Deck'])\n",
    "\n",
    "    features_to_scale = ['Age', 'SibSp', 'Parch', 'Fare', 'FamilySize']\n",
    "    scaler = StandardScaler()\n",
    "    data[features_to_scale] = scaler.fit_transform(data[features_to_scale])\n",
    "    data.drop('Cabin', axis=1, inplace=True)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T04:51:31.344265100Z",
     "start_time": "2023-10-11T04:51:31.337284600Z"
    }
   },
   "id": "4b62896dba021b53"
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values in training data: []\n",
      "Columns with NaN values in test data: []\n"
     ]
    }
   ],
   "source": [
    "train = preprocess_data_advanced(train)\n",
    "test = preprocess_data_advanced(test)\n",
    "\n",
    "print(\"Columns with NaN values in training data:\", train.columns[train.isnull().any()].tolist())\n",
    "print(\"Columns with NaN values in test data:\", test.columns[test.isnull().any()].tolist())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T04:51:32.338176300Z",
     "start_time": "2023-10-11T04:51:32.294283300Z"
    }
   },
   "id": "2b752b8458ac2a00"
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "def align_columns(train, test):\n",
    "    # Ensure test set has the same columns as the train set\n",
    "    missing_cols = set(train.columns) - set(test.columns)\n",
    "    for c in missing_cols:\n",
    "        test[c] = 0\n",
    "\n",
    "    # Ensure order of columns in test is same as in train\n",
    "    test = test[train.columns]\n",
    "\n",
    "    return train, test\n",
    "\n",
    "train, test = align_columns(train, test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T04:51:34.222921800Z",
     "start_time": "2023-10-11T04:51:34.213945400Z"
    }
   },
   "id": "1aadb056d07ed438"
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8435754189944135\n"
     ]
    },
    {
     "data": {
      "text/plain": "     PassengerId  Survived\n0            892         0\n1            893         0\n2            894         0\n3            895         0\n4            896         1\n..           ...       ...\n413         1305         0\n414         1306         1\n415         1307         0\n416         1308         0\n417         1309         0\n\n[418 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>1305</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>414</th>\n      <td>1306</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>415</th>\n      <td>1307</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>416</th>\n      <td>1308</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>417</th>\n      <td>1309</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>418 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=1000, max_depth=5, random_state=1)\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=1000, learning_rate=1.0, max_depth=8, random_state=1)\n",
    "lr_clf = LogisticRegression(max_iter=10000, random_state=1)\n",
    "\n",
    "r\n",
    "vote_clf = VotingClassifier(estimators=[('rf', rf_clf), ('gb', gb_clf), ('lr', lr_clf)], voting='soft')\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "vote_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "accuracy = vote_clf.score(X_val, y_val)\n",
    "print(\"Validation Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "if 'Survived' in test.columns:\n",
    "    X_test = test.drop(['PassengerId', 'Name', 'Ticket', 'Survived'], axis=1)\n",
    "else:\n",
    "    X_test = test.drop(['PassengerId', 'Name', 'Ticket'], axis=1)\n",
    "\n",
    "ensemble_predictions = vote_clf.predict(X_test)\n",
    "\n",
    "ensemble_result = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': ensemble_predictions})\n",
    "ensemble_result.to_csv('submission_ensemble.csv', index=False)\n",
    "\n",
    "\n",
    "ensemble_result = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': ensemble_predictions})\n",
    "ensemble_result\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T05:17:42.846452700Z",
     "start_time": "2023-10-11T05:17:37.435897100Z"
    }
   },
   "id": "bc0eb1de5888a6ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ff198d4d7609c2dc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
